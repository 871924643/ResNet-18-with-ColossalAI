{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lcDhlbkHZ7yw",
        "outputId": "eadd6eb5-ed5f-4f72-8e9e-88f63d7c837b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colossalai (from -r requirements.txt (line 1))\n",
            "  Downloading colossalai-0.3.6.tar.gz (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.66.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (7.4.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from colossalai->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from colossalai->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from colossalai->-r requirements.txt (line 1)) (24.0)\n",
            "Collecting pre-commit (from colossalai->-r requirements.txt (line 1))\n",
            "  Downloading pre_commit-3.7.0-py2.py3-none-any.whl (204 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.2/204.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from colossalai->-r requirements.txt (line 1)) (13.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from colossalai->-r requirements.txt (line 1)) (8.1.7)\n",
            "Collecting fabric (from colossalai->-r requirements.txt (line 1))\n",
            "  Downloading fabric-3.2.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contexttimer (from colossalai->-r requirements.txt (line 1))\n",
            "  Downloading contexttimer-0.3.3.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ninja (from colossalai->-r requirements.txt (line 1))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from colossalai->-r requirements.txt (line 1)) (0.4.2)\n",
            "Collecting einops (from colossalai->-r requirements.txt (line 1))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from colossalai->-r requirements.txt (line 1)) (2.6.4)\n",
            "Collecting ray (from colossalai->-r requirements.txt (line 1))\n",
            "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from colossalai->-r requirements.txt (line 1)) (0.1.99)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.10/dist-packages (from colossalai->-r requirements.txt (line 1)) (2.0.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from colossalai->-r requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->-r requirements.txt (line 5)) (2.0.1)\n",
            "Collecting invoke>=2.0 (from fabric->colossalai->-r requirements.txt (line 1))\n",
            "  Downloading invoke-2.2.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting paramiko>=2.4 (from fabric->colossalai->-r requirements.txt (line 1))\n",
            "  Downloading paramiko-3.4.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.9/225.9 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator>=5 (from fabric->colossalai->-r requirements.txt (line 1))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting deprecated>=1.2 (from fabric->colossalai->-r requirements.txt (line 1))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from google->colossalai->-r requirements.txt (line 1)) (4.12.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (2.1.5)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->colossalai->-r requirements.txt (line 1))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->colossalai->-r requirements.txt (line 1))\n",
            "  Downloading identify-2.5.35-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit->colossalai->-r requirements.txt (line 1))\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai->-r requirements.txt (line 1)) (6.0.1)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->colossalai->-r requirements.txt (line 1))\n",
            "  Downloading virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->colossalai->-r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->colossalai->-r requirements.txt (line 1)) (2.16.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray->colossalai->-r requirements.txt (line 1)) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray->colossalai->-r requirements.txt (line 1)) (1.0.8)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray->colossalai->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray->colossalai->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray->colossalai->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai->-r requirements.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2->fabric->colossalai->-r requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->colossalai->-r requirements.txt (line 1)) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit->colossalai->-r requirements.txt (line 1)) (67.7.2)\n",
            "Collecting bcrypt>=3.2 (from paramiko>=2.4->fabric->colossalai->-r requirements.txt (line 1))\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai->-r requirements.txt (line 1)) (42.0.5)\n",
            "Collecting pynacl>=1.5 (from paramiko>=2.4->fabric->colossalai->-r requirements.txt (line 1))\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->colossalai->-r requirements.txt (line 1))\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai->-r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->google->colossalai->-r requirements.txt (line 1)) (2.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->colossalai->-r requirements.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->colossalai->-r requirements.txt (line 1)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->colossalai->-r requirements.txt (line 1)) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->colossalai->-r requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray->colossalai->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray->colossalai->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray->colossalai->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray->colossalai->-r requirements.txt (line 1)) (2024.2.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai->-r requirements.txt (line 1)) (2.22)\n",
            "Building wheels for collected packages: colossalai, contexttimer\n",
            "  Building wheel for colossalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colossalai: filename=colossalai-0.3.6-py3-none-any.whl size=1389734 sha256=d3e12a9e9430eea7de7d80386675b9db09b09f69f1624806c72123c2a0831c25\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/52/8e/8ff9fb0a6ec328844d9344eb1e1adc29f3d05886adb2a3551a\n",
            "  Building wheel for contexttimer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contexttimer: filename=contexttimer-0.3.3-py3-none-any.whl size=5804 sha256=dc596c737ebf57bb4795e2f956ddd55d4388f65ae9853b03d072a50b566ee7ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/1c/da/cfd97201d88ccce214427fa84a5caeb91fef7c5a1b4c4312b4\n",
            "Successfully built colossalai contexttimer\n",
            "Installing collected packages: ninja, distlib, contexttimer, virtualenv, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nodeenv, invoke, identify, einops, deprecated, decorator, cfgv, bcrypt, pynacl, pre-commit, nvidia-cusparse-cu12, nvidia-cudnn-cu12, paramiko, nvidia-cusolver-cu12, ray, fabric, colossalai\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bcrypt-4.1.2 cfgv-3.4.0 colossalai-0.3.6 contexttimer-0.3.3 decorator-5.1.1 deprecated-1.2.14 distlib-0.3.8 einops-0.7.0 fabric-3.2.2 identify-2.5.35 invoke-2.2.0 ninja-1.11.1.1 nodeenv-1.8.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 paramiko-3.4.0 pre-commit-3.7.0 pynacl-1.5.0 ray-2.10.0 virtualenv-20.25.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "decorator"
                ]
              },
              "id": "70cfb79bb67d40c6a9dc328dfb55c6f0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufJbEyoFhI_c",
        "outputId": "dab4c522-9484-4edc-e1a2-4c022e45e51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr  6 04:40:15 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhbKaDLzhIuY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBlA6SR4aFSJ",
        "outputId": "dff9cf2d-bf18-47ad-d090-e764eed317f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/06/24 04:40:27] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "100%|██████████| 170498071/170498071 [00:04<00:00, 41226056.60it/s]\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 38.92936873435974 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 260.11876225471497 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "Epoch [1/10]:   0%|          | 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Epoch [1/10]: 100%|██████████| 500/500 [00:31<00:00, 15.70it/s, loss=1.38]\n",
            "Epoch [2/10]: 100%|██████████| 500/500 [00:30<00:00, 16.18it/s, loss=1.17]\n",
            "Epoch [3/10]: 100%|██████████| 500/500 [00:30<00:00, 16.14it/s, loss=0.989]\n",
            "Epoch [4/10]: 100%|██████████| 500/500 [00:30<00:00, 16.31it/s, loss=0.898]\n",
            "Epoch [5/10]: 100%|██████████| 500/500 [00:30<00:00, 16.65it/s, loss=0.841]\n",
            "Epoch [6/10]: 100%|██████████| 500/500 [00:31<00:00, 15.96it/s, loss=0.832]\n",
            "Epoch [7/10]: 100%|██████████| 500/500 [00:31<00:00, 15.98it/s, loss=0.884]\n",
            "Epoch [8/10]: 100%|██████████| 500/500 [00:31<00:00, 16.05it/s, loss=0.766]\n",
            "Epoch [9/10]: 100%|██████████| 500/500 [00:30<00:00, 16.59it/s, loss=0.753]\n",
            "Epoch [10/10]: 100%|██████████| 500/500 [00:30<00:00, 16.20it/s, loss=0.724]\n",
            "Accuracy of the model on the test images: 74.66 %\n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n"
          ]
        }
      ],
      "source": [
        "# train with torch DDP with fp32\n",
        "!colossalai run --nproc_per_node 1 train.py -c ./ckpt-fp32\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py -c ./ckpt-fp32 -e 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idgCaOOGwUsK",
        "outputId": "a6acf19e-3262-4bfb-97ed-cfb14761a89a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 74.66 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!colossalai run --nproc_per_node 1 train.py -c ./ckpt-fp16 -p torch_ddp_fp16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyjDG04KwPKE",
        "outputId": "eba7f998-d0ae-4296-9d71-03869635fcf9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/06/24 04:58:18] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.09728217124938965 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.11910271644592285 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "Epoch [1/30]:   0%|          | 1/500 [00:00<05:15,  1.58it/s, loss=2.65]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Epoch [1/30]: 100%|██████████| 500/500 [00:27<00:00, 18.41it/s, loss=1.59]\n",
            "Epoch [2/30]: 100%|██████████| 500/500 [00:27<00:00, 18.31it/s, loss=1.33]\n",
            "Epoch [3/30]: 100%|██████████| 500/500 [00:27<00:00, 18.38it/s, loss=1.28]\n",
            "Epoch [4/30]: 100%|██████████| 500/500 [00:27<00:00, 18.42it/s, loss=1.22]\n",
            "Epoch [5/30]: 100%|██████████| 500/500 [00:27<00:00, 18.33it/s, loss=1.12]\n",
            "Epoch [6/30]: 100%|██████████| 500/500 [00:26<00:00, 18.78it/s, loss=1.1]\n",
            "Epoch [7/30]: 100%|██████████| 500/500 [00:26<00:00, 18.80it/s, loss=1.07]\n",
            "Epoch [8/30]: 100%|██████████| 500/500 [00:27<00:00, 18.51it/s, loss=1.03]\n",
            "Epoch [9/30]: 100%|██████████| 500/500 [00:27<00:00, 18.49it/s, loss=1.02]\n",
            "Epoch [10/30]: 100%|██████████| 500/500 [00:26<00:00, 18.64it/s, loss=0.964]\n",
            "Epoch [11/30]: 100%|██████████| 500/500 [00:27<00:00, 18.12it/s, loss=0.915]\n",
            "Epoch [12/30]: 100%|██████████| 500/500 [00:27<00:00, 18.16it/s, loss=0.922]\n",
            "Epoch [13/30]: 100%|██████████| 500/500 [00:27<00:00, 18.27it/s, loss=0.796]\n",
            "Epoch [14/30]: 100%|██████████| 500/500 [00:27<00:00, 18.29it/s, loss=0.847]\n",
            "Epoch [15/30]: 100%|██████████| 500/500 [00:26<00:00, 18.72it/s, loss=0.819]\n",
            "Epoch [16/30]: 100%|██████████| 500/500 [00:27<00:00, 18.43it/s, loss=0.694]\n",
            "Epoch [17/30]: 100%|██████████| 500/500 [00:28<00:00, 17.76it/s, loss=0.769]\n",
            "Epoch [18/30]: 100%|██████████| 500/500 [00:27<00:00, 17.86it/s, loss=0.786]\n",
            "Epoch [19/30]: 100%|██████████| 500/500 [00:26<00:00, 18.61it/s, loss=0.641]\n",
            "Epoch [20/30]: 100%|██████████| 500/500 [00:26<00:00, 18.61it/s, loss=0.574]\n",
            "Epoch [21/30]: 100%|██████████| 500/500 [00:27<00:00, 18.50it/s, loss=0.68]\n",
            "Epoch [22/30]: 100%|██████████| 500/500 [00:26<00:00, 18.78it/s, loss=0.533]\n",
            "Epoch [23/30]: 100%|██████████| 500/500 [00:26<00:00, 18.56it/s, loss=0.545]\n",
            "Epoch [24/30]: 100%|██████████| 500/500 [00:26<00:00, 18.79it/s, loss=0.653]\n",
            "Epoch [25/30]: 100%|██████████| 500/500 [00:25<00:00, 19.58it/s, loss=0.573]\n",
            "Epoch [26/30]: 100%|██████████| 500/500 [00:25<00:00, 19.50it/s, loss=0.471]\n",
            "Epoch [27/30]: 100%|██████████| 500/500 [00:26<00:00, 18.88it/s, loss=0.522]\n",
            "Epoch [28/30]: 100%|██████████| 500/500 [00:27<00:00, 18.31it/s, loss=0.345]\n",
            "Epoch [29/30]: 100%|██████████| 500/500 [00:26<00:00, 18.71it/s, loss=0.38]\n",
            "Epoch [30/30]: 100%|██████████| 500/500 [00:27<00:00, 18.28it/s, loss=0.433]\n",
            "Accuracy of the model on the test images: 75.83 %\n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py -c ./ckpt-fp16 -e 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjjZ6lOl0mfJ",
        "outputId": "59ee79f4-613f-40f8-b2db-30ad17292c78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 68.15 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py -c ./ckpt-fp16 -e 30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPHgRiVq0sw1",
        "outputId": "1d5403b5-d780-48a3-d841-572e0457ab0c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 75.84 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!colossalai run --nproc_per_node 1 train.py -c ./ckpt-low_level_zero -p low_level_zero"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYKJFBau0ym3",
        "outputId": "d7e8bde6-e604-486a-bc08-337a4db15a07"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/06/24 05:13:44] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.09273910522460938 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.10875511169433594 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "Epoch [1/30]:   0%|          | 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Epoch [1/30]: 100%|██████████| 500/500 [00:37<00:00, 13.50it/s, loss=1.55]\n",
            "Epoch [2/30]: 100%|██████████| 500/500 [00:37<00:00, 13.48it/s, loss=1.35]\n",
            "Epoch [3/30]: 100%|██████████| 500/500 [00:36<00:00, 13.74it/s, loss=1.19]\n",
            "Epoch [4/30]: 100%|██████████| 500/500 [00:35<00:00, 14.22it/s, loss=1.21]\n",
            "Epoch [5/30]: 100%|██████████| 500/500 [00:34<00:00, 14.31it/s, loss=1.09]\n",
            "Epoch [6/30]: 100%|██████████| 500/500 [00:35<00:00, 13.94it/s, loss=1.07]\n",
            "Epoch [7/30]: 100%|██████████| 500/500 [00:37<00:00, 13.43it/s, loss=1.02]\n",
            "Epoch [8/30]: 100%|██████████| 500/500 [00:35<00:00, 13.94it/s, loss=0.953]\n",
            "Epoch [9/30]: 100%|██████████| 500/500 [00:36<00:00, 13.87it/s, loss=0.972]\n",
            "Epoch [10/30]: 100%|██████████| 500/500 [00:34<00:00, 14.35it/s, loss=0.868]\n",
            "Epoch [11/30]: 100%|██████████| 500/500 [00:36<00:00, 13.81it/s, loss=0.923]\n",
            "Epoch [12/30]: 100%|██████████| 500/500 [00:36<00:00, 13.65it/s, loss=0.858]\n",
            "Epoch [13/30]: 100%|██████████| 500/500 [00:36<00:00, 13.82it/s, loss=0.886]\n",
            "Epoch [14/30]: 100%|██████████| 500/500 [00:35<00:00, 13.92it/s, loss=0.853]\n",
            "Epoch [15/30]: 100%|██████████| 500/500 [00:36<00:00, 13.60it/s, loss=0.762]\n",
            "Epoch [16/30]: 100%|██████████| 500/500 [00:36<00:00, 13.74it/s, loss=0.619]\n",
            "Epoch [17/30]: 100%|██████████| 500/500 [00:36<00:00, 13.70it/s, loss=0.8]\n",
            "Epoch [18/30]: 100%|██████████| 500/500 [00:37<00:00, 13.47it/s, loss=0.776]\n",
            "Epoch [19/30]: 100%|██████████| 500/500 [00:36<00:00, 13.88it/s, loss=0.667]\n",
            "Epoch [20/30]: 100%|██████████| 500/500 [00:36<00:00, 13.76it/s, loss=0.66]\n",
            "Epoch [21/30]: 100%|██████████| 500/500 [00:36<00:00, 13.55it/s, loss=0.574]\n",
            "Epoch [22/30]: 100%|██████████| 500/500 [00:38<00:00, 13.07it/s, loss=0.588]\n",
            "Epoch [23/30]: 100%|██████████| 500/500 [00:36<00:00, 13.64it/s, loss=0.629]\n",
            "Epoch [24/30]: 100%|██████████| 500/500 [00:36<00:00, 13.61it/s, loss=0.661]\n",
            "Epoch [25/30]: 100%|██████████| 500/500 [00:35<00:00, 13.92it/s, loss=0.717]\n",
            "Epoch [26/30]: 100%|██████████| 500/500 [00:37<00:00, 13.47it/s, loss=0.471]\n",
            "Epoch [27/30]: 100%|██████████| 500/500 [00:37<00:00, 13.48it/s, loss=0.447]\n",
            "Epoch [28/30]: 100%|██████████| 500/500 [00:36<00:00, 13.81it/s, loss=0.483]\n",
            "Epoch [29/30]: 100%|██████████| 500/500 [00:37<00:00, 13.42it/s, loss=0.363]\n",
            "Epoch [30/30]: 100%|██████████| 500/500 [00:36<00:00, 13.61it/s, loss=0.589]\n",
            "Accuracy of the model on the test images: 76.66 %\n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py -c ./ckpt-low_level_zero -e 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSbnIN8b50BS",
        "outputId": "f2df1358-d89f-4202-f0e7-0e1b649e7621"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 67.28 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py -c ./ckpt-low_level_zero -e 30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkLFdmBn58m5",
        "outputId": "7b5880b1-43bf-4534-93b4-889939c80901"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 76.65 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}